---
title: "Tracking tree phenology of Nature View Park in Buffalo"
author: "Yuhao Xie"
subtitle: null
---

# Introduction
***
Phenology has been proven as a sensitive and integrative indicator of climate variability and vegetation growth responses to climate change (X. Zhao, K. Tan, 2011). The understanding of phenology brings significant insight into both climate and vegetation interactions and their impacts on different spatial and temporal scales (Y. He, 2013). NDVI and EVI are two most widely used indexes in vegetation phenology study.This project aims at tracking phenology change of forest at Nature View Park in Buffalo in the past decade. Further analysis will estimate the Start of Season(SOS) and End of Season(EOS) for each year during the last decade illustrate a evidence of potential climate change.  
<br><br>

The study is very fashionable and use quite good data. 
Pros:
Fashionable idea, up to date method, clear structure
Cons:
For the regression part, usually we need validation on the regression result to make research more convincible. This can be concluded in the result or conclusion part

# Data and methods  
***
##Data acquisition
The traditional way of monitoring forest phenology uses remote sensing data such as Landsat TM or MODIS data which is efficient in large-scale studies.

In this study, I use the Application for Extracting and Exploring Analysis Ready Samples(AρρEEARS) to download MODIS data.[AρρEEARS](https://lpdaacsvc.cr.usgs.gov/appeears/) provides a simple and efficient way to access and transform geospatial data from a variety of federal data archives. It enables users to subset geospatial datasets using spatial, temporal, and band/layer parameters. Two types of sample requests are available: point samples for geographic coordinates and area samples for spatial areas via vector polygons.

This project bases on both two satellites of MODIS system, Aqua and Terra, to extract the NDVI of the Nature View Park in Buffalo. The 16-day NDVI layer of MODIS Vegetation Indices product are used. Each satellite provides global vegetation indices including NDVI, EVI and LAI every 16 days with 1km spatial resolution. But Aqua and Terra are on the two different orbits which let them have a 8 days interval between each other for visiting a same place. Thus, we can have 8 days interval NDVI data for the study area rely on combining data from both two satellites. The time period of data is from 01/01/2008 to 11/01/2018. AρρEEARS also provides API for submitting request and downloading data from R.  

Load required packages for using AρρEEARS API and further wrangling on data(you may need to install some packages):
```{r, message=F, warning=F}
library(httr)
library(jsonlite)
library(RCurl)
library(ggplot2)
library(dplyr)
library(lubridate)
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(cache=TRUE)  # cache the results for quick compiling
```
<br>

AρρEEARS API requires user to have an account and log in before use further functions. You can sign up an account on [AρρEEARS website](https://lpdaacsvc.cr.usgs.gov/appeears/). Since most of people visit this project don't have account for that. I downloaded the required data by the code chunks below and pushed it to my github repository and provide codes in the next section for downloading data from my repository.  
For using the API, using the code below to log in with your username and password first and check the log in status.
```{r, warning=F,eval=FALSE} 
#log in the system with NASA EarthData account username and password
secret <- base64_enc(paste("your username", "password", sep = ":"))
response <- POST("https://lpdaacsvc.cr.usgs.gov/appeears/api/login", 
                 add_headers("Authorization" = paste("Basic", gsub("\n", "", secret)),
                             "Content-Type" = "application/x-www-form-urlencoded;charset=UTF-8"), 
                 body = "grant_type=client_credentials")

#check log in status
token_response <- prettify(toJSON(content(response), auto_unbox = TRUE))
token_response
response_p <- GET("https://lpdaacsvc.cr.usgs.gov/appeears/api/product")
product_response <- toJSON(content(response_p), auto_unbox = TRUE)
```
<br>

The API requires a JavaScript Object Notation(JSON) format task file for submitting a request. the task file should includes the sample type, period, product id and layer name. For point sample, only the geographic coordiates needed. Since the spatial resolution is 1km on MODIS data, one pixel of the image should be enough to cover the whole study area. As the task file below describes, the 16-days NDVI data of the study area with 1km resolution from both two satellites from 2008 to 2018 will be included in request. It can take a few seconds even minutes for completing the request.
```{r,eval=FALSE}
# create a task request
task <- '{
          "task_type": "point",
"task_name": "my-task",
"params":{
"dates": [
{
  "startDate": "01-01-2008",
  "endDate": "11-01-2018"
}],
  "layers": [
  {
"product": "MOD13A2.006",
  "layer": "_1_km_16_days_NDVI"
  },
  {
"product": "MYD13A2.006",
  "layer": "_1_km_16_days_NDVI"
  }],
  "coordinates": [
  {
  "latitude": 43.0444,
  "longitude": -78.7833
  }]
}
}'
task <- fromJSON(task)
task <- toJSON(task, auto_unbox=TRUE)

#submit the task request
token <- paste("Bearer", fromJSON(token_response)$token)
response <- POST("https://lpdaacsvc.cr.usgs.gov/appeears/api/task", body = task, encode = "json", 
                 add_headers(Authorization = token, "Content-Type" = "application/json"))
task_response <- prettify(toJSON(content(response), auto_unbox = TRUE))
task_response
```
<br>

The point sample requset results in two csv files including all the acquired data and quality descriptions. The API does not support bath download, a for loop is used to download both to csv files to the working directory.
```{r,eval=FALSE}
#check task bundle
token <- paste("Bearer", fromJSON(token_response)$token)
response <- GET(paste("https://lpdaacsvc.cr.usgs.gov/appeears/api/bundle/", task_id, sep = ""), add_headers(Authorization = token))
bundle_response <- prettify(toJSON(content(response), auto_unbox = TRUE))
bundle_response

#Download file
#get csv file id and name
file_list<-fromJSON(bundle_response)$files
file_id<-file_list$file_id[file_list$file_type=="csv"]
file_name<-file_list$file_name[file_list$file_type=="csv"]

# create a destination directory to store the file in
dest_dir <- getwd()
filepath <- paste(dest_dir, file_name, sep = '/')
suppressWarnings(dir.create(dirname(filepath)))

# write the file to disk using the destination directory and file name 
for(i in 1:length(file_id)){
  response <- GET(paste("https://lpdaacsvc.cr.usgs.gov/appeears/api/bundle/", task_id, '/', file_id[i], sep = ""),
                write_disk(filepath[i], overwrite = TRUE), progress(), add_headers(Authorization = token))
  }

#read and view data
data<-read.csv(file_name)
View(data)
```
<br><br>

##Methods
This page use the code chunk below to download required data from my github repository. [RCurl](https://cran.r-project.org/web/packages/RCurl/index.html) package is used for getting file through HTTPS url.
```{r}
#read data from my github repository
data1<-read.csv(text=getURL("https://raw.githubusercontent.com/AdamWilsonLabEDU/geo503-2018-finalproject-Henryxie1003/master/my-task-MOD13A2-006-results.csv"))
data2<-read.csv(text=getURL("https://raw.githubusercontent.com/AdamWilsonLabEDU/geo503-2018-finalproject-Henryxie1003/master/my-task-MYD13A2-006-results.csv"))
```
Example of data from Terra MODIS:
```{r,echo=FALSE}
kable(data1) %>%kable_styling(c("striped", "bordered")) %>%scroll_box(width = "100%", height = "300px")
```
<br>

Since cloud and other climatic influence is inevitable on remote sensing data, the MODIS product provide data quality information for each pixel on the image. There are four levels for generally describe the quality of each observation and each level corresponds to a unique code. The code stands for cloud cover is used for filtering out the cloudy observations in both two datasets.
```{r}
#data wrangling
#filter out cloudy pixel
data1_nonCloud<-filter(data1,MOD13A2_006__1_km_16_days_VI_Quality_MODLAND!='0b10')
data2_nonCloud<-filter(data2,MYD13A2_006__1_km_16_days_VI_Quality_MODLAND!='0b10')
```
<br>

As mentioned in the previous section above, two MODIS satellites have a 8 days interval for visiting a same place. Data from two 16-days datasets are combined to get one 8-days dataset for the study area. vegetation phenology is usually illustrated by vegetation index vs number of days in the year of observations. Years and number of days are extracted from the `Date` column for each observation.
```{r}
#combine two data frame and rename column
data1_new<-data1_nonCloud%>%select(Date,MOD13A2_006__1_km_16_days_NDVI)
colnames(data1_new)[2]<-'NDVI'
data2_new<-data2_nonCloud%>%select(Date,MYD13A2_006__1_km_16_days_NDVI)
colnames(data2_new)[2]<-'NDVI'
data_combine<-rbind(data1_new,data2_new)

#add year and number of days marker to each observation
data_combine$Year<-substr(data_combine$Date,1,4)
data_combine$NumDays<-yday(data_combine$Date)
```
The final dataset after wrangling:
```{r,echo=FALSE}
kable(data_combine) %>%kable_styling(c("striped", "bordered")) %>%scroll_box(width = "100%", height = "300px")
```
<br>

Vegetation phenological parameters such as start of season (SOS), end of season (EOS), and length of growing season (LGS) have been broadly used in studies of interactions between climate vegetation, especially for forest research. SOS and EOS are defined as the first and last day of having significant photosynthetic activity in the year. NDVI is the most commonly used index to denote photosynthetic activity. The simple way to detect SOS and EOS is setting a threshold on NDVI and considering the first day it go over the threshold in spring as SOS and the below the threshold in autumn as EOS. Since the MODIS data only provide NDVI every 8 days, a linear regression model is built respectively on spring and autumn data for each year. Data from 50 to 150 days in each year are considered as spring data for building a spring model and autumn data is from 250 to 350 days. Threshold is set on 0.5 for detect SOS and EOS.
```{r}
#estimate SOS and EOS
SOS_range<-data_combine%>%filter(NumDays>=50&NumDays<=150)
SOS<-data.frame(Year=character(),SOS=double())
for (i in 2008:2018) {
  SOS_t<-lm(NumDays~NDVI, SOS_range%>%filter(Year==i))%>%predict(data.frame(NDVI = c(0.5)))
  SOS<-rbind(SOS,c(i,SOS_t))
}
names(SOS) <- c("Year", "SOS")
SOS$Year<-as.character(SOS$Year)

EOS_range<-data_combine%>%filter(NumDays>=250&NumDays<=350)
EOS<-data.frame(Year=integer(),SOS=double())
for (i in 2008:2017) {
  EOS_t<-lm(NumDays~NDVI, EOS_range%>%filter(Year==i))%>%predict(data.frame(NDVI = c(0.5)))
  EOS<-rbind(EOS,c(i,EOS_t))
}
names(EOS) <- c("Year", "EOS")
EOS$Year<-as.character(EOS$Year)
```
<br><br>

#Result
***
```{r,echo=FALSE,message=FALSE,warning=FALSE}
ggplot(data_combine,aes(x=NumDays,y=NDVI,col=Year))+
  geom_smooth(method='auto',span=0.5,fill=NA,se=F)+
  ylim(0.0,1.0)+
  labs(x='Number of days',y='NDVI')+
  theme_bw()
```
<br>

```{r,echo=FALSE,message=FALSE,warning=FALSE}
plot_SOS<-ggplot(data = SOS,aes(x=Year,y=SOS,group=1))+
  geom_line(colour='blue')+
  theme_bw()
plot_SOS
```
<br>

```{r,echo=FALSE,message=FALSE,warning=FALSE}
plot_EOS<-ggplot(data = EOS,aes(x=Year,y=EOS,group=1))+
  geom_line(colour='red')+
  theme_bw()
plot_EOS
```
<br><br>

# Conclusions
***

<br><br>

# References
***
